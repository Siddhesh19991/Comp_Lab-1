---
title: "Q2_V2"
author: "Simon Jorstedt"
date: "`r Sys.Date()`"
output: pdf_document
---





# Question 2 - EM Algorithm
```{r Problem Setup, echo=F, message=F, warning=F}
# Setup

library(magrittr)
library(dplyr)

# Read in the data, and create a column with clear indication whether an
# observation is censored or not. To be clear, cens=2 indicates that an
# observation *is* censored, and thus "yes".
df_prodfails <- read.csv("censoredproc.csv", sep = ";") %>%
  mutate(censored = c("no", "yes")[(cens == 2)+1])
```

A certain type of product fails after random times. We are given a dataset of observations of these fail times. Most observations represent the exact fail time, but for some observations, the time that a product was discovered to have failed is recorded instead. In other words, these observations are censored. Assuming that fail times and time until discovery are independent, this would imply that the uncensored observations can be modeled by some probability distribution $X \sim D$, and the censored observations can be modeled by the distribution of a random variable $X + Y$ where $Y$ is a random variable from the distribution of the time between a product failing and it being discovered. In the instructions, it is stated that the censored measurements are left censored, which makes sense in this context.

## Question 2.1
```{r, echo=F, fig.align='center', out.width="70%"}
# Question 2.1

# Create plot grid
layout(mat=matrix(c(1,2, 3), nrow = 1, byrow = T))

hist(df_prodfails$time,
     freq = F,
     main = "All recorded times",
     xlab = "Fail time")

hist(df_prodfails %>% filter(censored == "no") %>% extract2(1),
     freq=F,
     main = "Uncensored fail times",
     xlab = "Fail time")

hist(df_prodfails %>% filter(censored == "yes") %>% extract2(1),
     freq=F,
     main = "Censored fail times",
     xlab = "Fail time")

# Add exponential density
lambda_estim <- 1/(df_prodfails %>% filter(censored == "yes") %>% extract2(1) %>% mean())
x_seq <- seq(0, 10, 0.1)
points(x_seq, dexp(x_seq, rate=lambda_estim), type="l")

# Set figure title
mtext("Figure 2.1: Density of fail times", side=3, outer=TRUE, line=-1)

```

All three histograms in Figure 2.1 appear approximately exponential. The density for all recorded times is not significantly different from the uncensored fail times, but it should be noted that the censored fail times only make up about $23$ % of the observations.

## Question 2.2
We now assume that all uncensored observations $x_i$, $i = 1, \cdots, n$, pairwise independently come from an exponential distribution with rate $\lambda$, and thus density $f(x) = \lambda e^{-\lambda x}$. For the censored observations, we will model the underlying true fail times $z_i$, $i = 1, \cdots, m$, each conditioned on the censored value $y_i$, $i = 1, \cdots, m$, as observations of a truncated exponential distribution:

$$Z | Y=y_i \sim \text{TruncExp}(\lambda, 0, y_i)$$

with density

$$g(z | y) = 

\begin{Bmatrix}
\frac{\lambda \exp(-\lambda z)}{1-\exp(-\lambda y)} & 0 \leq z \leq y\\
0 & \text{otherwise}
\end{Bmatrix}.$$

Thus the Likelihood of our observed data is

$$L(\lambda; X, Z|Y) = \Bigg( \prod_{i=1}^n f(x_i) \Bigg) \cdot \Bigg( \prod_{i=1}^m g(Z_i | y_i) \Bigg).$$

Observe that the Likelihood above is a random variable, since it is a function of the random variables $Z_i|y_i$, $i = 1, \cdots, m$.

# Question 2.3
Because of our uncertainty in the true fail times $z_i$, we will employ the EM algorithm to estimate the MLE of $\lambda$. In the E step, we will construct the function $Q(\lambda, \lambda^{(t)}) = E_{*}[\log L(\lambda; X, Z|Y)]$, where the $*$ indicates that we take the expectation with respect to $Z | Y=y_i \sim \text{TruncExp}(\lambda^{(t)}, 0, y_i)$. This function is quite intricate, and can in the end be formulated as

$$Q(\lambda, \lambda^{(t)}) = n \cdot \ln \lambda - n + m \ln(\lambda^{(t)}) - \lambda^{(t)} \cdot \sum_ {i=1}^m E[Z|Y=y_i] - \sum_ {i=1}^m \ln \Big( 1-\exp(-\lambda^{(t)} y_i) \Big).$$

For clarity, $n$ and $m$ are the number of \textit{un}censored and censored observations respectively in the data. The first two terms in expression above are the log likelihood contribution from the uncensored data, and the other terms are the log likelihood contribution from the censored data. The remaining expectation in the expression above is found to be

$$E_*[Z |Y=y_i] = \frac{1 -\exp(-\lambda^{(t)}y_i) - y_i \lambda^{(t)} \exp(-\lambda^{(t)} y_i)}{\lambda^{(t)} \Big( 1 - \exp(-\lambda^{(t)} y_i) \Big)}$$

In the M step of the EM algorithm, we simply optimise $Q(\lambda, \lambda^{(t)})$ with respect to $\lambda$, and set $\lambda^{(t+1)} = \text{argmax}_{\lambda} Q(\lambda, \lambda^{(t)})$.

## Question 2.4
Now we implement the EM-algorithm.

```{r EM Algorithm Setup}
# Question 2.4

Expected_Trunc_Exp <- function(rate, b=Inf){
  # Returns the expected value of an exp distribution truncated on [0, b].
  
  numerator <- (-exp(-rate*b) + 1 + -b*rate*exp(-rate*b))
  denominator <- (rate*(1-exp(-rate*b)))
  
  return(numerator / denominator)
}

Q <- function(lambda, lambda_t){
  # Function for the expected value of the Likelihood of the data
  
  censored_data <- df_prodfails %>% filter(censored == "yes")
  n <- df_prodfails %>% filter(censored == "no") %>% extract2(1) %>% length()
  m <- censored_data$time %>% length()
  
  # This term represents the log likelihood contribution from the fully
  # observed data to the expectation
  term1 <- n * log(lambda) - n
  
  # The following terms make up the log likelihood contribution from the
  # censored observations to the expectation
  term2 <- m * log(lambda_t)
  
  term3 <- - lambda_t * sum(Expected_Trunc_Exp(lambda_t, b=censored_data$time))
  
  term4 <- - sum(log(1-exp(-lambda_t * censored_data$time)))
  
  return(term1 + term2 + term3 + term4)
}


# The EM Algorithm
EM_algorithm <- function(lambda_start = 100, epsilon = 0.001){
  # Setup
  k <- 0
  k_max <- 100
  lambda_t = lambda_start
  stop <- FALSE
  
  # Keep iterating until convergence is reached
  while(stop != TRUE){
    k <- k + 1
    
    # E Step: Q is already (implicitly) constructed
    
    # M Step
    lambda_new <- optimise(f = Q,
                           lambda_t = lambda_t,
                           maximum = T,
                           interval=c(0, 10^3))$maximum
    
    # Evaluate stop conditions
    stop <- k <= k_max | abs(lambda_t - lambda_new) < epsilon
    
    # Accept the new lambda_t (if the algorithm has not been stopped)
    lambda_t <- lambda_new
  }
  
  cat("Optimal lambda:", lambda_new, "\n")
  cat("Iterations:", k)
}

EM_algorithm()
```

When we implement the EM algorithm above, we run into an interesting error. The estimate of $\lambda$ tends to infinity (bounded by an arbitrary parameter interval we set). This is because our formulation of $Q(\lambda, \lambda^{(t)})$ grows strictly with $\lambda$. This is likely due to some error in our derivation.



